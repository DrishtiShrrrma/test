{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2c9c9e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:21:39.084708Z",
          "iopub.status.busy": "2024-11-06T17:21:39.084365Z",
          "iopub.status.idle": "2024-11-06T17:25:38.497526Z",
          "shell.execute_reply": "2024-11-06T17:25:38.496338Z"
        },
        "id": "2f2c9c9e",
        "papermill": {
          "duration": 239.466156,
          "end_time": "2024-11-06T17:25:38.500081",
          "exception": false,
          "start_time": "2024-11-06T17:21:39.033925",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pip3-autoremove\n",
        "!pip-autoremove torch torchvision torchaudio -y\n",
        "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install unsloth\n",
        "!pip install --upgrade --no-cache-dir transformers\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3df4bba",
      "metadata": {
        "id": "e3df4bba",
        "papermill": {
          "duration": 0.04921,
          "end_time": "2024-11-06T17:25:38.600151",
          "exception": false,
          "start_time": "2024-11-06T17:25:38.550941",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n",
        "* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n",
        "* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n",
        "* With [PR 26037](https://github.com/huggingface/transformers/pull/26037), we support downloading 4bit models **4x faster**! [Our repo](https://huggingface.co/unsloth) has Llama, Mistral 4bit models.\n",
        "* [**NEW**] We make Phi-3 Medium / Mini **2x faster**! See our [Phi-3 Medium notebook](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b3f665b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:25:38.700225Z",
          "iopub.status.busy": "2024-11-06T17:25:38.699884Z",
          "iopub.status.idle": "2024-11-06T17:26:52.121815Z",
          "shell.execute_reply": "2024-11-06T17:26:52.121000Z"
        },
        "id": "1b3f665b",
        "outputId": "11c2c758-7a3f-4db9-9e6d-c565b026bd78",
        "papermill": {
          "duration": 73.474911,
          "end_time": "2024-11-06T17:26:52.124296",
          "exception": false,
          "start_time": "2024-11-06T17:25:38.649385",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "fbe455450a054e2b8cdcf30aea7cd301",
            "2bfc94f6e2a84017a9734c0b613eeddf",
            "300ecde831e64a1b8d04d96975987d19",
            "3d72322df344422ea07a945e19a67371",
            "18c1a5ba53e543e0ba8ae8b573625236",
            "987717d14ac748599b9d18d1a66de429",
            "a66f895f86a34f358a8a96c2dedad0e0",
            "bb4c1cac51c74a899d62860145aca79f",
            "f92e42a1b6ad4da08baf0b901e974052"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2024.11.2: Fast Qwen2 patching. Transformers = 4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbe455450a054e2b8cdcf30aea7cd301",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.55G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bfc94f6e2a84017a9734c0b613eeddf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "300ecde831e64a1b8d04d96975987d19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/4.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d72322df344422ea07a945e19a67371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18c1a5ba53e543e0ba8ae8b573625236",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "987717d14ac748599b9d18d1a66de429",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a66f895f86a34f358a8a96c2dedad0e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb4c1cac51c74a899d62860145aca79f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f92e42a1b6ad4da08baf0b901e974052",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/162M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.11.2 patched 28 layers with 0 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "#Loading the model that was saved after fine tuning for classification\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen2.5-7B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27009a48",
      "metadata": {
        "id": "27009a48",
        "papermill": {
          "duration": 0.051429,
          "end_time": "2024-11-06T17:26:52.228398",
          "exception": false,
          "start_time": "2024-11-06T17:26:52.176969",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac69fa2e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:26:52.336388Z",
          "iopub.status.busy": "2024-11-06T17:26:52.335432Z",
          "iopub.status.idle": "2024-11-06T17:26:52.340536Z",
          "shell.execute_reply": "2024-11-06T17:26:52.339657Z"
        },
        "id": "ac69fa2e",
        "papermill": {
          "duration": 0.061174,
          "end_time": "2024-11-06T17:26:52.342510",
          "exception": false,
          "start_time": "2024-11-06T17:26:52.281336",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966f219a",
      "metadata": {
        "id": "966f219a",
        "papermill": {
          "duration": 0.051725,
          "end_time": "2024-11-06T17:26:52.445944",
          "exception": false,
          "start_time": "2024-11-06T17:26:52.394219",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n",
        "\n",
        "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "\n",
        "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
        "\n",
        "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n",
        "\n",
        "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ee2792",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:26:52.549683Z",
          "iopub.status.busy": "2024-11-06T17:26:52.549344Z",
          "iopub.status.idle": "2024-11-06T17:26:58.902290Z",
          "shell.execute_reply": "2024-11-06T17:26:58.901354Z"
        },
        "id": "82ee2792",
        "outputId": "ca0bcab2-91b5-4513-c6dc-6df3fe99c58c",
        "papermill": {
          "duration": 6.407131,
          "end_time": "2024-11-06T17:26:58.904360",
          "exception": false,
          "start_time": "2024-11-06T17:26:52.497229",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "ae4595fd6e0e45f9b5edc412ea70cdf0",
            "28f23b6ce406423b9cdeee1d07dafeac",
            "5c1dd2e776d943928c64c17778f86842",
            "511ef72282a446d2870a6912dbc82a0f",
            "271c9056151f4113a0c9552781a48a0f"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae4595fd6e0e45f9b5edc412ea70cdf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28f23b6ce406423b9cdeee1d07dafeac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FINNLP-train.csv:   0%|          | 0.00/11.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c1dd2e776d943928c64c17778f86842",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FINNLP-dev.csv:   0%|          | 0.00/3.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "511ef72282a446d2870a6912dbc82a0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Train split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "271c9056151f4113a0c9552781a48a0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Dev split:   0%|          | 0/453 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset=load_dataset('1-800-SHARED-TASKS/COLING-2025-FINNLP-FMD')\n",
        "train_dataset=dataset['Train']\n",
        "dev_dataset=dataset['Dev']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c565eac5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:26:59.011452Z",
          "iopub.status.busy": "2024-11-06T17:26:59.010925Z",
          "iopub.status.idle": "2024-11-06T17:29:15.325041Z",
          "shell.execute_reply": "2024-11-06T17:29:15.324184Z"
        },
        "papermill": {
          "duration": 136.415863,
          "end_time": "2024-11-06T17:29:15.373384",
          "exception": false,
          "start_time": "2024-11-06T17:26:58.957521",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "9535680d380a4d6799e655f7551bf98c"
          ]
        },
        "id": "c565eac5",
        "outputId": "02c23ea9-00a4-45a5-db69-54221273756e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9535680d380a4d6799e655f7551bf98c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import re\n",
        "def preprocess_func(examples):\n",
        "  length=len(examples['claim'])\n",
        "  for i in range(length):\n",
        "    if re.search(r'(?=Claim).*(?= Example:)',examples['justification'][i]):\n",
        "      examples['claim'][i]=examples['claim'][i]+'- '+re.findall(r'[^(?:Claim: )].*(?= Example:)',examples['justification'][i])[0]\n",
        "      examples['justification'][i]=re.sub(r'(?:Claim: ).* Example: ','',examples['justification'][i])\n",
        "\n",
        "  return {'claim':examples['claim'],'justification':examples['justification']}\n",
        "\n",
        "train_dataset_new=train_dataset.map(preprocess_func,batched=True)\n",
        "dev_dataset_new=dev_dataset.map(preprocess_func,batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a311d7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:29:15.484163Z",
          "iopub.status.busy": "2024-11-06T17:29:15.483374Z",
          "iopub.status.idle": "2024-11-06T17:29:15.633384Z",
          "shell.execute_reply": "2024-11-06T17:29:15.632576Z"
        },
        "id": "34a311d7",
        "outputId": "9f1fb1c6-2bc1-4f76-b6c3-920c1ba03c77",
        "papermill": {
          "duration": 0.207106,
          "end_time": "2024-11-06T17:29:15.635205",
          "exception": false,
          "start_time": "2024-11-06T17:29:15.428099",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "e715f06f56bf4c02a4d7817b36645e45"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e715f06f56bf4c02a4d7817b36645e45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Training for both classification and explanation\n",
        "prompt_template = \"\"\"Below is an instruction that describes a task, paired with a claim and justification that provides further context. Please write a response that appropriately completes the request.\n",
        "### Instruction:\n",
        "The goal is to classify the text as true/not_enough_info/false. Choose the correct category from these options and add an explanation after classification:\n",
        "1: True\n",
        "2: NEI\n",
        "3: False\n",
        "Your response must be in the following format:\n",
        "Prediction: Your_Prediction Explanation: Your_Explanation\n",
        "\n",
        "### Claim:\n",
        "{claim}\n",
        "### Justification:\n",
        "{justification}\n",
        "### Response:\n",
        "Prediction: {label} Explanation: {expl}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "def formatting_prompts_func(examples):\n",
        "    texts = []\n",
        "    for claim, justification, label, explanation in zip(examples['claim'], examples['justification'], examples['label'], examples['evidence']):\n",
        "        formatted_text = prompt_template.format(claim=claim, justification=justification, label=label, expl=explanation) + EOS_TOKEN\n",
        "        texts.append(formatted_text)\n",
        "    return {\"text\": texts}\n",
        "formatted_train_dataset=train_dataset_new.map(formatting_prompts_func, batched = True,)\n",
        "formatted_dev_dataset=dev_dataset_new.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98820ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:29:15.742984Z",
          "iopub.status.busy": "2024-11-06T17:29:15.742378Z",
          "iopub.status.idle": "2024-11-06T17:29:15.760236Z",
          "shell.execute_reply": "2024-11-06T17:29:15.759404Z"
        },
        "id": "f98820ff",
        "outputId": "c3a29981-5059-47ad-feb6-790957459e08",
        "papermill": {
          "duration": 0.073929,
          "end_time": "2024-11-06T17:29:15.762558",
          "exception": false,
          "start_time": "2024-11-06T17:29:15.688629",
          "status": "completed"
        },
        "tags": [],
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task, paired with a claim and justification that provides further context. Write a response that appropriately completes the request.\\n### Instruction:\\nThe goal is to classify the text as true/not_enough_info/false. Choose the correct category from these options and add an explanation after classification:\\n1: True\\n2: NEI\\n3: False\\nYour response must be in the following format:\\nPrediction: Your_Prediction Explanation: Your_Explanation\\n\\n### Claim:\\nChecking the Facts About \\'Dreamers\\'\\n### Justification:\\nFirst introduced in Congress in 2001 and last revisited in 2017, the so-called DREAM Act (which stands for the Development, Relief, and Education for Alien Minors Act) was aimed at providing a path to permanent residency in the United States for children of undocumented immigrants. Every attempt to pass the legislation has failed to date, as politicians continue to kick the can down the road to the next administration. DREAM Act However, in June 2012, the DREAM Act begat DACA (Deferred Action for Childhood Arrivals), an executive action signed by President Obama that allowed qualified undocumented minors to apply for work permits and protection from deportation. To be eligible, applicants had to be under the age of 31, must have arrived in the U.S. before turning 16, lived in the country continuously since 2007, be enrolled in school or possess the equivalent of a high school diploma, and never been convicted of a serious crime. DACA By the time the Trump administration rescinded the program in September 2017 (on the spurious grounds that it was an abuse of executive power), an estimated 800,000 people  most of them under the age of 25  had applied for DACA protection. In honor of the ill-fated DREAM Act, and to reflect that they have a dream of someday becoming citizens, they have come to be known as \"Dreamers.\" rescinded 800,000 With DACA gone, the Dreamers\\' future once again rests with Congress. Members of both parties have vowed to pass legislation granting them protections comparable to DACA\\'s, an idea supported by the majority of the American people. Even President Trump backs the effort, having suggested to the New York Times that Dreamers be given a path to citizenship: supported suggested Over a period of 10 to 12 years, somebody does a great job, they work hard, that gives incentive to do a great job. Whatever they\\'re doing, if they do a great job, I think it\\'s a nice thing to have the incentive of, after a period of years, being able to become a citizen.  A vocal minority opposes that idea, however, and some of its detractors have taken to social media to spread anti-Dreamer (and other anti-immigrant) propaganda. One example making the rounds on Facebook consists of a list of so-called \"fun facts\" intended to persuade readers that Dreamers are bad people and any government efforts to help them amount to a \"scam\":   These two groups differ not only in size, but also in attributes such as how well educated their members are and how many have criminal records. This is because DACA imposed strict requirements in those areas. For purposes of this fact check, we\\'re defining \"Dreamers\" as those who actually enrolled in the DACA program between 2012 and 2017. We\\'ve chosen this route for two reasons: one, it has been, to date, the working definition used by major news and polling organizations such as the New York Times, Associated Press, and the Pew Research Center; and two, in the single instance where we determined that the \"Dreamers fun facts\" meme reported a statistic accurately (the military participation of Dreamers), it pertained (and only makes sense if it pertains) to the group of actual DACA enrollees, not the larger DACA-eligible group. (Barring a change in regulations, non-DACA undocumented immigrants cannot enlist in the military.) Associated Press CLAIM: \"792,000 Dreamers (88 percent) are over 25 years old.\" . Only about 280,000 (35 percent) of the 800,000 Dreamers who were active DACA recipients as of September 2017 were over 25 years old. None are older than 36 because of the age-of-entry requirements imposed by DACA. The average age of Dreamers is 24. [Source: Pew Research Center] Pew Research Center CLAIM: \"900 Dreamers (less than 1 percent) serve in our military.\" .  Generally speaking, undocumented immigrants aren\\'t allowed to join the U.S. military, so this statistic can only apply to DACA enrollees, who were granted special permission to enlist in 2014. granted As of September 2017, there were close to 900 Dreamers serving in the military thanks to that program, according to the Pentagon. That is less than .1 percent of all DACA recipients. For comparison, according to a USA Today report .4 percent of the general population currently serves in the military. [Sources: USA Today; Pew Research Center] USA Today Pew Research Center CLAIM: \"743,000 Dreamers (83 percent) do not have a college degree.\" . In a 2017 survey of approximately 3,000 Dreamers, the portion of those aged 25 or older who said they hold a four-year college degree (or higher) was close to 35 percent. That means 65 percent (approximately 520,000) do not yet have a college degree. Comparing that to the larger U.S. population, 2015 census figures say that roughly 32 percent of Americans 25 or older have a least a four-year college degree (meaning 68 percent do not). [Sources: T. Wong DACA Survey; U.S. Census Bureau] survey T. Wong DACA Survey U.S. Census Bureau CLAIM: \"189,000 Dreamers dropped out of high school early (That is roughly 21 percent).\" . The only statistic we were able to find comparable to this applied not to Dreamers, but to the larger population of potentially DACA-eligible immigrants. According to a 2014 study, roughly 20 percent of those aged 19 or older had not completed high school or the equivalent (as compared to a 5.9 percent high school dropout rate for the entire U.S. population). We found no such statistic for DACA enrollees, who in any case would have been required under government guidelines to be \"currently in school, have graduated or obtained a certificate of completion from high school, have obtained a general education development (GED) certificate, or are an honorably discharged veteran of the Coast Guard or Armed Forces of the United States.\" [Sources: Migration Policy Institute; U.S. Citizenship and Immigration Services; National Center for Education Statistics] Migration Policy Institute U.S. Citizenship and Immigration Services National Center for Education Statistics CLAIM: \"9,000 Dreamers (1 percent) are incarcerated.\"  We were unable to find any sources documenting the claim that 9,000 Dreamers are (or were) incarcerated. It may be that the 1 percent figure was loosely derived from a Cato Institute policy brief which said that the incarceration rate among the 1.1 to 1.9 million immigrants who were otherwise DACA-eligible in 2015 was .98 percent. (What\\'s most interesting about that figure is that it\\'s actually a lower incarceration rate than that of the native-born population, according to the Cato Institute). brief The closest comparable statistic we found for actual DACA enrollees came from an accounting by USCIS of the number of those whose \"deferred action\" status was terminated between 2012 and 2017 due to criminal convictions or arrests: 2,030 (or approximately .25 percent of the entire Dreamer population). [Sources: Cato Institute; U.S. Citizenship and Immigration Services] Cato Institute CLAIM: \"657,000 Dreamers (73 percent) receive some form of welfare.\" . By law, undocumented immigrants (including DACA recipients) are not eligible for means-tested welfare benefits such as cash assistance, food stamps, or Medicaid. Under a provision of DACA, enrollees who reached retirement age after having worked and paid taxes in the United States for at least 10 years could have qualified for Social Security and Medicare benefits. [Source: National Immigration Law Center] law National Immigration Law Center It is important in policymaking matters to carefully weigh the facts and how populations will be affected. One can only hope that those same legislators do not govern by meme. Bier, David. \"Five Myths About DACA.\"\\rThe Washington Post. 7 September 2017. Broder, Tanya, Moussavian, Avideh, and Blazer Jonathan. \"Overview of Immigrant Eligibility for Federal Programs.\"\\rNational Immigration Law Center. December 2015. Chishti, Muzaffar and Bolter, Jessica. \"Trump Administration Rescinds DACA, Fueling Renewed Push in Congress and the Courts to Protect Dreamers.\"\\r Migration Policy Institute. 15 September 2017. Dickerson, Caitlin. \"What Is DACA? Who Are the Dreamers? Here Are the Basics.\"\\rThe New York Times. 23 January 2018. Gonzalez, Roberto, et al. \"Taking Giant Leaps Forward.\"\\rCenter for American Progress. 22 June 2017. Greenwood, Max. \"Poll: Nearly 9 in 10 Want DACA Recipients to Stay in U.S.\"\\rThe Hill. 18 January 2018. Haberman, Maggie, Rogers, Katie, and Shear, Michael. \"Trump Says He Is Open to a Path to Citizenship for \\'Dreamers.\\'\"\\rThe New York Times. 24 January 2018. Horton, Alex. \"The Military Looked to \\'Dreamers\\' to Use Their Vital Skills. Now the U.S. Might Deport Them.\"\\rThe Washington Post. 7 September 2017. Kessler, Glenn. \"The Debate Over DACA: A Guide to the Numbers Used by Politicians.\"\\rThe Washington Post. 23 January 2018. Korte, Gregory, Gomez, Alan, and Johnson, Kevin. \"Trump Administration Struggles With Fate of 900 Dreamers Serving in the Military.\"\\rUSA Today. 7 September 2017. Krogstad, Jens Manuel. \"DACA Has Shielded Nearly 790,000 Young Unauthorized Immigrants From Deportation.\"\\rPew Research Center. 1 September 2017. Landgrave, Michelangelo and Nowraster, Alex. \"The Dreamer Incarceration Rate.\"\\rCato Institute. 30 August 2017. Lopez, Gustavo and Krogstad, Jens Manuel. \"Key Facts About Unauthorized Immigrants Enrolled in DACA.\"\\rPew Research Center. 25 September 2017. McHugh, Margie. \"Diploma, Please: Promoting Educational Attainment for DACA- and Potential DREAM Act-Eligible Youth.\"\\rMigration Policy Institute. September 2014. Ryan, Camille L. and Bauman, Kurt. \"Educational Attainment in the United States: 2015.\"\\rU.S. Census Bureau. March 2016. Siskin, Alison. \"Noncitizen Eligibility for Federal Public Assistance: An Overview.\"\\rCongressional Research Service. 12 December 2016. Wong, Tom K. \"New Study of DACA Beneficiaries Shows Positive Economic and Educational Outcomes.\"\\rCenter for American Progress. 18 October 2016. Wong, Tom K., et al. \"DACA Recipients\\' Economic and Educational Gains Continue to Grow.\"\\rCenter for American Progress. 28 August 2017. Zong, Jie, et al. \"A Profile of Current DACA Recipients by Education, Industry, and Occupation.\"\\rMigration Policy Institute. November 2017. National Center for Education Statistics. \"Dropout Rates.\"\\rAccessed 25 January 2018. National Immigration Law Center. \"DACA and DAPA Access to Federal Health and Economic Support Programs.\"\\r30 January 2015. United States Citizenship and Immigration Services. \"DACA Terminations Related to Criminal and Gang Activity by Fiscal Year.\"\\r2017.\\n### Response:\\nPrediction: True Explanation: First introduced in Congress in 2001 and last revisited in 2017, the so-called DREAM Act (which stands for the Development, Relief, and Education for Alien Minors Act) was aimed at providing a path to permanent residency in the United States for children of undocumented immigrants. Every attempt to pass the legislation has failed to date, as politicians continue to kick the can down the road to the next administration.However, in June 2012, the DREAM Act begat DACA (Deferred Action for Childhood Arrivals), an executive action signed by President Obama that allowed qualified undocumented minors to apply for work permits and protection from deportation. To be eligible, applicants had to be under the age of 31, must have arrived in the U.S. before turning 16, lived in the country continuously since 2007, be enrolled in school or possess the equivalent of a high school diploma, and never been convicted of a serious crime.By the time the Trump administration rescinded the program in September 2017 (on the spurious grounds that it was an abuse of executive power), an estimated 800,000 people  most of them under the age of 25  had applied for DACA protection. In honor of the ill-fated DREAM Act, and to reflect that they have a dream of someday becoming citizens, they have come to be known as \"Dreamers.\"With DACA gone, the Dreamers\\' future once again rests with Congress. Members of both parties have vowed to pass legislation granting them protections comparable to DACA\\'s, an idea supported by the majority of the American people. Even President Trump backs the effort, having suggested to the New York Times that Dreamers be given a path to citizenship:For purposes of this fact check, we\\'re defining \"Dreamers\" as those who actually enrolled in the DACA program between 2012 and 2017. We\\'ve chosen this route for two reasons: one, it has been, to date, the working definition used by major news and polling organizations such as the New York Times, Associated Press, and the Pew Research Center; and two, in the single instance where we determined that the \"Dreamers fun facts\" meme reported a statistic accurately (the military participation of Dreamers), it pertained (and only makes sense if it pertains) to the group of actual DACA enrollees, not the larger DACA-eligible group. (Barring a change in regulations, non-DACA undocumented immigrants cannot enlist in the military.)Only about 280,000 (35 percent) of the 800,000 Dreamers who were active DACA recipients as of September 2017 were over 25 years old. None are older than 36 because of the age-of-entry requirements imposed by DACA. The average age of Dreamers is 24. [Source: Pew Research Center]Generally speaking, undocumented immigrants aren\\'t allowed to join the U.S. military, so this statistic can only apply to DACA enrollees, who were granted special permission to enlist in 2014.As of September 2017, there were close to 900 Dreamers serving in the military thanks to that program, according to the Pentagon. That is less than .1 percent of all DACA recipients. For comparison, according to a USA Today report .4 percent of the general population currently serves in the military. [Sources: USA Today; Pew Research Center]In a 2017 survey of approximately 3,000 Dreamers, the portion of those aged 25 or older who said they hold a four-year college degree (or higher) was close to 35 percent. That means 65 percent (approximately 520,000) do not yet have a college degree. Comparing that to the larger U.S. population, 2015 census figures say that roughly 32 percent of Americans 25 or older have a least a four-year college degree (meaning 68 percent do not). [Sources: T. Wong DACA Survey; U.S. Census Bureau]We found no such statistic for DACA enrollees, who in any case would have been required under government guidelines to be \"currently in school, have graduated or obtained a certificate of completion from high school, have obtained a general education development (GED) certificate, or are an honorably discharged veteran of the Coast Guard or Armed Forces of the United States.\" [Sources: Migration Policy Institute; U.S. Citizenship and Immigration Services; National Center for Education Statistics]It may be that the 1 percent figure was loosely derived from a Cato Institute policy brief which said that the incarceration rate among the 1.1 to 1.9 million immigrants who were otherwise DACA-eligible in 2015 was .98 percent. (What\\'s most interesting about that figure is that it\\'s actually a lower incarceration rate than that of the native-born population, according to the Cato Institute).The closest comparable statistic we found for actual DACA enrollees came from an accounting by USCIS of the number of those whose \"deferred action\" status was terminated between 2012 and 2017 due to criminal convictions or arrests: 2,030 (or approximately .25 percent of the entire Dreamer population). [Sources: Cato Institute; U.S. Citizenship and Immigration Services]By law, undocumented immigrants (including DACA recipients) are not eligible for means-tested welfare benefits such as cash assistance, food stamps, or Medicaid. Under a provision of DACA, enrollees who reached retirement age after having worked and paid taxes in the United States for at least 10 years could have qualified for Social Security and Medicare benefits. [Source: National Immigration Law Center]<|endoftext|>'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset_new['text'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf77e43",
      "metadata": {
        "id": "5bf77e43",
        "papermill": {
          "duration": 0.053607,
          "end_time": "2024-11-06T17:29:15.869368",
          "exception": false,
          "start_time": "2024-11-06T17:29:15.815761",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "275e4444",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:29:16.014344Z",
          "iopub.status.busy": "2024-11-06T17:29:16.013346Z",
          "iopub.status.idle": "2024-11-06T17:29:21.975919Z",
          "shell.execute_reply": "2024-11-06T17:29:21.974845Z"
        },
        "id": "275e4444",
        "outputId": "57c4dc9b-5c1b-47e5-ecf2-9cbd4eb3f846",
        "papermill": {
          "duration": 6.019289,
          "end_time": "2024-11-06T17:29:21.978477",
          "exception": false,
          "start_time": "2024-11-06T17:29:15.959188",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "88035b9533fd437b9749473611f893a2"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88035b9533fd437b9749473611f893a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer,DataCollatorForCompletionOnlyLM\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "response_template = \"### Response:\\n\"\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = formatted_train_dataset,\n",
        "    eval_dataset = formatted_dev_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator=collator,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "#     packing = True, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 8,\n",
        "        gradient_accumulation_steps = 2,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs=5,\n",
        "        eval_steps = 25,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        save_strategy='epoch',\n",
        "        eval_strategy='steps'\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7929256",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:29:22.087190Z",
          "iopub.status.busy": "2024-11-06T17:29:22.086853Z",
          "iopub.status.idle": "2024-11-06T17:29:22.093768Z",
          "shell.execute_reply": "2024-11-06T17:29:22.092787Z"
        },
        "id": "d7929256",
        "outputId": "f7e79dc2-858b-48ac-c4fb-9526f4fd347d",
        "papermill": {
          "duration": 0.063347,
          "end_time": "2024-11-06T17:29:22.095747",
          "exception": false,
          "start_time": "2024-11-06T17:29:22.032400",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "5.936 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990ddea9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T17:29:22.207098Z",
          "iopub.status.busy": "2024-11-06T17:29:22.206155Z",
          "iopub.status.idle": "2024-11-07T02:58:53.804907Z",
          "shell.execute_reply": "2024-11-07T02:58:53.803859Z"
        },
        "id": "990ddea9",
        "outputId": "1843e696-fd6a-4d19-a558-a01386b407ef",
        "papermill": {
          "duration": 34171.658169,
          "end_time": "2024-11-07T02:58:53.808309",
          "exception": false,
          "start_time": "2024-11-06T17:29:22.150140",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,500 | Num Epochs = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 935\n",
            " \"-____-\"     Number of trainable parameters = 40,370,176\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 9:28:48, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.124900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# trainer_stats = trainer.train()\n",
        "from unsloth import unsloth_train\n",
        "# unsloth_train fixes gradient_accumulation_steps\n",
        "trainer_stats = unsloth_train(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64cd8c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-07T02:58:53.918389Z",
          "iopub.status.busy": "2024-11-07T02:58:53.917834Z",
          "iopub.status.idle": "2024-11-07T02:59:07.460298Z",
          "shell.execute_reply": "2024-11-07T02:59:07.459296Z"
        },
        "id": "f64cd8c1",
        "outputId": "5025cd5a-c091-45a9-b53f-fb6f9f39ec4b",
        "papermill": {
          "duration": 13.599511,
          "end_time": "2024-11-07T02:59:07.462522",
          "exception": false,
          "start_time": "2024-11-07T02:58:53.863011",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "32817490f48d4ea89f5636cf0465e9ba",
            "c29ba7131ed045878865af27dd64de99",
            "0d09a931b67d48ad9d90d35eaf62d6e1",
            "0b3da20c81254454be635a289e7bafc7",
            "2b0ded0e22514ca199be2495d4d24fea"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32817490f48d4ea89f5636cf0465e9ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/574 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c29ba7131ed045878865af27dd64de99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d09a931b67d48ad9d90d35eaf62d6e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/162M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to https://huggingface.co/jebish7/qwen2.5-7b-fmd-5-full\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b3da20c81254454be635a289e7bafc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b0ded0e22514ca199be2495d4d24fea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# model.save_pretrained(\"lora_model\") # Local saving\n",
        "# tokenizer.save_pretrained(\"lora_model\")\n",
        "model.push_to_hub(\"minemaster01/qwen2.5-7b-fmd-5-full\", token = \"hf_token\") # Online saving\n",
        "tokenizer.push_to_hub(\"minemaster01/qwen2.5-7b-fmd-5-full\", token = \"hf_token\") # Online saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d9957a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-07T02:59:07.574004Z",
          "iopub.status.busy": "2024-11-07T02:59:07.573657Z",
          "iopub.status.idle": "2024-11-07T02:59:07.581403Z",
          "shell.execute_reply": "2024-11-07T02:59:07.580444Z"
        },
        "id": "7d9957a8",
        "outputId": "14dc05ed-3554-496f-b5dc-a2f2ff6fb096",
        "papermill": {
          "duration": 0.065097,
          "end_time": "2024-11-07T02:59:07.583262",
          "exception": false,
          "start_time": "2024-11-07T02:59:07.518165",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34167.7171 seconds used for training.\n",
            "569.46 minutes used for training.\n",
            "Peak reserved memory = 10.582 GB.\n",
            "Peak reserved memory for training = 4.646 GB.\n",
            "Peak reserved memory % of max memory = 71.786 %.\n",
            "Peak reserved memory for training % of max memory = 31.518 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 34655.985276,
      "end_time": "2024-11-07T02:59:12.175551",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-11-06T17:21:36.190275",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}